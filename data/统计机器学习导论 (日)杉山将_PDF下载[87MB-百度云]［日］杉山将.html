统计机器学习导论/(日)杉山将 PDF下载 ［日］杉山将 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711159679
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711159679
<p>书名:统计机器学习导论/(日)杉山将</p><p>作者:［日］ 杉山将</p><p>页数:352</p><p>定价:¥89.0</p><p>出版社:机械工业出版社</p><p>出版日期:2017-07-01</p><p>ISBN:9787111596790</p><p><h2>本书特色</h2></p>[<p>
本书对机器学习的关键知识点进行了全面讲解，帮助读者顺利完成从理论到实践的过渡。书中首先介绍用于描述机器学习算法的统计与概率的知识，接着详细分析机器学习技术的两类主要方法——生成方法和判别方法，后深入研究了如何使机器学习算法在实际应用中发挥更大的作用。本书提供程序源代码，便于读者进行数据分析实践。本书适合高等院校计算机、统计等专业的研究生和高年级本科生阅读，同时也适合相关领域的技术人员参考。
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书对机器学习的关键知识点进行了全面讲解，帮助读者顺利完成从理论到实践的过渡。书中首先介绍用于描述机器学习算法的统计与概率的知识，接着详细分析机器学习技术的两类主要方法——生成方法和判别方法，后深入研究了如何使机器学习算法在实际应用中发挥更大的作用。本书提供程序源代码，便于读者进行数据分析实践。本书适合高等院校计算机、统计等专业的研究生和高年级本科生阅读，同时也适合相关领域的技术人员参考。</p>]<p><h2>作者简介</h2></p>[<p>【加照片】Masashi Sugiyama，东京大学教授，拥有东京工业大学计算机科学博士学位，研究兴趣包括机器学习与数据挖掘的理论、算法和应用，涉及信号处理、图像处理、机器人控制等。2007年获得IBM学者奖，以表彰其在机器学习领域非平稳性方面做出的贡献。2011年获得日本信息处理协会颁发的Nagao特别研究奖，以及日本文部科学省颁发的青年科学家奖，以表彰其对机器学习密度比范型的贡献。</p>]<p><h2>目录</h2></p>
    目录译者序前言作者简介**部分绪论第1章统计机器学习1.1学习的类型1.2机器学习任务举例1.2.1监督学习1.2.2非监督学习1.2.3进一步的主题1.3本书结构第二部分概率与统计第2章随机变量与概率分布2.1数学基础2.2概率2.3随机变量和概率分布2.4概率分布的性质2.4.1期望、中位数和众数2.4.2方差和标准差2.4.3偏度、峰度和矩2.5随便变量的变换第3章离散概率分布的实例3.1离散均匀分布3.2二项分布3.3超几何分布3.4泊松分布3.5负二项分布3.6几何分布第4章连续概率分布的实例4.1连续均匀分布4.2正态分布4.3伽马分布、指数分布和卡方分布4.4Beta分布4.5柯西分布和拉普拉斯分布4.6t分布和F分布第5章多维概率分布5.1联合概率分布5.2条件概率分布5.3列联表5.4贝叶斯定理5.5协方差与相关性5.6独立性第6章多维概率分布的实例6.1多项分布6.2多元正态分布6.3狄利克雷分布6.4威沙特分布第7章独立随机变量之和7.1卷积7.2再生性7.3大数定律7.4中心极限定理第8章概率不等式8.1联合界8.2概率不等式8.2.1马尔可夫不等式和切尔诺夫不等式8.2.2坎泰利不等式和切比雪夫不等式8.3期望不等式8.3.1琴生不等式8.3.2赫尔德不等式和施瓦茨不等式8.3.3闵可夫斯基不等式8.3.4康托洛维奇不等式8.4独立随机变量和的不等式8.4.1切比雪夫不等式和切尔诺夫不等式8.4.2霍夫丁不等式和伯恩斯坦不等式8.4.3贝内特不等式第9章统计估计9.1统计估计基础9.2点估计9.2.1参数密度估计9.2.2非参数密度估计9.2.3回归和分类9.2.4模型选择9.3区间估计9.3.1基于正态样本期望的区间估计9.3.2bootstrap置信区间9.3.3贝叶斯置信区间第10章假设检验10.1假设检验基础10.2正态样本期望的检验10.3尼曼皮尔森引理10.4列联表检验10.5正态样本期望差值检验10.5.1无对应关系的两组样本10.5.2有对应关系的两组样本10.6秩的无参检验10.6.1无对应关系的两组样本10.6.2有对应关系的两组样本10.7蒙特卡罗检验第三部分统计模式识别的生成式方法第11章通过生成模型估计的模式识别11.1模式识别的公式化11.2统计模式识别11.3分类器训练的准则11.3.1*大后验概率规则11.3.2*小错误分类率准则11.3.3贝叶斯决策规则11.3.4讨论11.4生成式方法和判别式方法第12章极大似然估计12.1定义12.2高斯模型12.3类后验概率的计算12.4Fisher线性判别分析12.5手写数字识别12.5.1预备知识12.5.2线性判别分析的实现12.5.3多分类器方法第13章极大似然估计的性质13.1一致性13.2渐近无偏性13.3渐近有效性13.3.1一维的情况13.3.2多维的情况13.4渐近正态性13.5总结第14章极大似然估计的模型选择14.1模型选择14.2KL散度14.3AIC信息论准则14.4交叉检验14.5讨论第15章高斯混合模型的极大似然估计15.1高斯混合模型15.2极大似然估计15.3梯度上升算法15.4EM算法第16章非参数估计16.1直方图方法16.2问题描述16.3核密度估计16.3.1Parzen 窗法16.3.2利用核的平滑16.3.3带宽的选择16.4*近邻密度估计16.4.1*近邻距离16.4.2*近邻分类器第17章贝叶斯推理17.1贝叶斯预测分布17.1.1定义17.1.2与极大似然估计的比较17.1.3计算问题17.2共轭先验17.3*大后验估计17.4贝叶斯模型选择第18章边缘相似的解析近似18.1拉普拉斯近似18.1.1高斯密度估计18.1.2例证18.1.3应用于边际似然逼近18.1.4贝叶斯信息准则18.2变分近似18.2.1变分贝叶斯*大期望算法18.2.2与一般*大期望法的关系第19章预测分布的数值近似19.1蒙特卡罗积分19.2重要性采样19.3采样算法19.3.1逆变换采样19.3.2拒绝采样19.3.3马尔可夫链蒙特卡罗方法第20章贝叶斯混合模型20.1高斯混合模型20.1.1贝叶斯公式化20.1.2变分推断20.1.3吉布斯采样20.2隐狄利克雷分配模型20.2.1主题模型20.2.2贝叶斯公式化20.2.3吉布斯采样第四部分统计机器学习的判别式方法第21章学习模型21.1线性参数模型21.2核模型21.3层次模型第22章*小二乘回归22.1*小二乘法22.2线性参数模型的解决方案22.3*小二乘法的特性22.4大规模数据的学习算法22.5层次模型的学习算法第23章具有约束的*小二乘回归23.1子空间约束的*小二乘23.2��2约束的*小二乘23.3模型选择第24章稀疏回归24.1��1约束的*小二乘24.2解决��1约束的*小二乘24.3稀疏学习的特征选择24.4若干扩展24.4.1广义��1约束*小二乘24.4.2�沺约束*小二乘24.4.3��1 ��2约束*小二乘24.4.4��1,2约束*小二乘24.4.5迹范数约束*小二乘第25章稳健回归25.1��2损失*小化的非稳健性25.2��1损失*小化25.3Huber损失*小化25.3.1定义25.3.2随机梯度算法25.3.3迭代加权*小二乘25.3.4��1约束Huber损失*小化25.4Tukey 损失*小化第26章*小二乘分类器26.1基于*小二乘回归的分类器26.20/1损失和间隔2
