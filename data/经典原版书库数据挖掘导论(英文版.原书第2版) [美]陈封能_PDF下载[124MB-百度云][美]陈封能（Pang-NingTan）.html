经典原版书库数据挖掘导论(英文版.原书第2版)/[美]陈封能 PDF下载 [美]陈封能（Pang-NingTan） 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711163788
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711163788
<p>书名:经典原版书库数据挖掘导论(英文版.原书第2版)/[美]陈封能</p><p>作者:[美]陈封能（Pang-NingTan）</p><p>页数:836</p><p>定价:¥199.0</p><p>出版社:机械工业出版社</p><p>出版日期:2018-01-01</p><p>ISBN:9787111637882</p><p><h2>本书特色</h2></p>[<p>
本书从算法的角度介绍数据挖掘所使用的主要原理与技术。为了更好地理解数据挖掘技术如何用于各种类型的数据，研究这些原理与技术是至关重要的。<br/>本书所涵盖的主题包括：数据预处理、预测建模、关联分析、聚类分析、异常检测和避免错误发现。通过介绍每个主题的基本概念和算法，为读者提供将数据挖掘应用于实际问题所需的必要背景以及使用方法。<br/>
</p>]<p><h2>内容简介</h2></p>[<p>本书从算法的角度介绍数据挖掘所使用的主要原理与技术。为了更好地理解数据挖掘技术如何用于各种类型的数据，研究这些原理与技术是至关重要的。
本书所涵盖的主题包括：数据预处理、预测建模、关联分析、聚类分析、异常检测和避免错误发现。通过介绍每个主题的基本概念和算法，为读者提供将数据挖掘应用于实际问题所需的必要背景以及使用方法。</p>]<p><h2>作者简介</h2></p>[<p>陈封能（Pang-Ning Tan） 密歇根州立大学计算机科学与工程系教授，主要研究方向是数据挖掘、数据库系统、网络空间安全、网络分析等。<br/></p>]<p><h2>目录</h2></p>
    第1章　绪论	11.1　什么是数据挖掘	41.2　数据挖掘要解决的问题	51.3　数据挖掘的起源	71.4　数据挖掘任务	91.5　本书组织结构	131.6　文献注释	151.7　习题	21第2章　数据	232.1　数据类型	262.1.1　属性与度量	272.1.2　数据集的类型	342.2　数据质量	422.2.1　测量和数据收集问题	422.2.2　关于应用的问题	492.3　数据预处理	502.3.1　聚集	512.3.2　抽样	522.3.3　维归约	562.3.4　特征子集选择	582.3.5　特征创建	612.3.6　离散化和二元化	632.3.7　变量变换	692.4　相似性和相异性的度量	712.4.1　基础	722.4.2　简单属性之间的相似度和相异度		742.4.3　数据对象之间的相异度	762.4.4　数据对象之间的相似度	782.4.5　邻近度度量的例子	792.4.6　互信息	88* 2.4.7　核函数	90* 2.4.8　Bregman散度	942.4.9　邻近度计算问题	962.4.10　选择正确的邻近度度量	982.5　文献注释	1002.6　习题	105第3章　分类：基本概念和技术	1133.1　基本概念	1143.2　一般的分类框架	1173.3　决策树分类器	1193.3.1　构建决策树的基本算法	1213.3.2　表示属性测试条件的方法	1243.3.3　选择属性测试条件的方法	1273.3.4　决策树归纳算法	1363.3.5　示例：Web机器人检测	1383.3.6　决策树分类器的特征	1403.4　模型的过拟	1473.5　模型选择	1563.5.1　验证集应用	1563.5.2　模型复杂度合并	1573.5.3　统计范围估计	1623.5.4　决策树的模型选择	1623.6　模型评估	1643.6.1　保持方法	1653.6.2　交叉验证	1653.7　超参数的使用	1683.7.1　超参数选择	1683.7.2　嵌套交叉验证	1703.8　模型选择和评估中的陷阱	1723.8.1　训练集和测试集之间的重叠	1723.8.2　使用验证错误率作为泛化错误率*3.9　模型比较	1733.9.1　估计准确率的置信区间	1743.9.2　比较两个模型的性能	1753.10　文献注释	1763.11　习题	185第4章　分类：其他技术	1934.1　分类器的种类	1934.2　基于规则的分类器	1954.2.1　基于规则的分类器原理	1974.2.2　规则集的属性	1984.2.3　规则提取的直接方法	1994.2.4　规则提取的间接方法	2044.2.5　基于规则的分类器的特点	2064.3　*近邻分类器	2084.3.1　算法	2094.3.2　*近邻分类器的特点	2104.4　朴素贝叶斯分类器	2124.4.1　概率论基础	2134.4.2　朴素贝叶斯假设	2184.5　贝叶斯网络	2274.5.1　图表示	2274.5.2　推理与学习	2334.5.3　贝叶斯网络的特点	2424.6　logistic回归	2434.6.1　logistic回归用作广义线性模型	2444.6.2　学习模型参数	2454.6.3　logistic回归模型的特点	2484.7　人工神经网络	2494.7.1　感知机	2504.7.2　多层神经网络	2544.7.3　人工神经网络的特点	2614.8　深度学习	2624.8.1　使用协同损失函数	2634.8.2　使用响应激活函数	2664.8.3　正则化	2684.8.4　模型参数的初始化	2714.8.5　深度学习的特点	2754.9　支持向量机	2764.9.1　分离超平面的边缘	2764.9.2　线性SVM	2784.9.3　软边缘SVM	2844.9.4　非线性SVM	2904.9.5　SVM的特点	2944.10　组合方法	2964.10.1　组合方法的基本原理	2974.10.2　构建组合分类器的方法	2974.10.3　偏置–方差分解	3004.10.4　装袋	3024.10.5　提升	3054.10.6　随机森林	3104.10.7　组合方法的实验比较	3124.11　类不平衡问题	3134.11.1　类不平衡的分类器构建	3144.11.2　带类不平衡的性能评估	3184.11.3　寻找*优的评分阈值	3224.11.4　综合评估性能	3234.12　多类问题	3304.13　文献注释	3334.14　习题	345第5章　关联分析：基本概念和算法	3575.1　预备知识	3585.2　频繁项集的产生	3625.2.1　先验原理	3635.2.2　Apriori算法的频繁项集产生	3645.2.3　候选项集的产生与剪枝	3685.2.4　支持度计数	3735.2.5　计算复杂度	3775.3　规则的产生	3805.3.1　基于置信度的剪枝	3805.3.2　Apriori算法中规则的产生	3815.3.3　示例：美国国会投票记录	3825.4　频繁项集的紧凑表示	3845.4.1　极大频繁项集	3845.4.2　闭项集	386*5.5　其他产生频繁项集的方法	389*5.6　FP增长算法	3935.6.1　FP树表示法	3945.6.2　FP增长算法的频繁项集产生	3975.7　关联模式的评估	4015.7.1　兴趣度的客观度量	4025.7.2　多个二元变量的度量	4145.7.3　辛普森悖论	4165.8　倾斜支持度分布的影响	4185.9　文献注释	4245.10　习题	438第6章　关联分析：高级概念	4516.1　处理分类属性	4516.2　处理连续属性	4546.2.1　基于离散化的方法	4546.2.2　基于统计学的方法	4586.2.3　非离散化方法	4606.3　处理概念分层	4626.4　序列模式	4646.4.1　预备知识	4656.4.2　序列模式发现	468* 6.4.3　时限约束	473* 6.4.4　可选计数方案	4776.5　子图模式	4796.5.1　预备知识	4806.5.2　频繁子图挖掘	4836.5.3　候选生成	4876.5.4　候选剪枝	4936.5.5　支持度计数	493*6.6　非频繁模式	4936.6.1　负模式	4946.6.2　负相关模式	4956.6.3　非频繁模式、负模式和负相关模式比较	4966.6.4　挖掘有趣的非频繁模式的技术	4986.6.5　基于挖掘负模式的技术	4996.6.6　基于支持度期望的技术	5016.7　文献注释	5056.8　习题	510第7章　聚类分析：基本概念和算法	5257.1　概述	5287.1.1　什么是聚类分析	5287.1.2　聚类的不同类型	5297.1.3　簇的不同类型	5317.2　K均值	5347.2.1　K均值算法	5357.2.2　K均值：附加的问题	5447.2.3　二分K均值	5477.2.4　K均值和不同的簇类型	5487.2.5　优点与缺点	5497.2.6　K均值作为优化问题	5497.3　凝聚层次聚类	5547.3.1　基本凝聚层次聚类算法	5557.3.2　特殊技术	5577.3.3　簇邻近度的Lance-Williams公式	5627.3.4　层次聚类的主要问题	5637.3.5　离群点	5647.3.6　优点与缺点	5657.4　DBSCAN	5657.4.1　传统的密度：基于中心的方法	5657.4.2　DBSCAN算法	5677.4.3　优点与缺点	5697.5　簇评估	5717.5.1　概述	5717.5.2　无监督簇评估：使用凝聚度和分离度	5747.5.3　无监督簇评估：使用邻近度矩阵	5827.5.4　层次聚类的无监督评估	5857.5.5　确定正确的簇个数	5877.5.6　聚类趋势	5887.5.7　簇有效性的监督度量	5897.5.8　评估簇有效性度量的显著性	5947.5.9　簇有效性度量的选择	5967.6　文献注释	5977.7　习题	603第8章　聚类分析：其他问题与算法	6138.1　数据、簇和聚类算法的特性	6148.1.1　示例：比较K均值和DBSCAN	6148.1.2　数据特性	6158.1.3　簇特性	6178.1.4　聚类算法的一般特性	6198.2　基于原型的聚类	6218.2.1　模糊聚类	6218.2.2　使用混合模型的聚类	6278.2.3　自组织映射	6378.3　基于密度的聚类	6448.3.1　基于网格的聚类	6448.3.2　子空间聚类	6488.3.3　DENCLUE：基于密度聚类的一种基于核的方案	6528.4　基于图的聚类	6568.4.1　稀疏化	6578.4.2　*小生成树聚类	6588.4.3　OPOSSUM：使用METIS的稀疏相似度*优划分	6598.4.4　Chameleon：使用动态建模的层次聚类	6608.4.5　谱聚类	6668.4.6　共享*近邻相似度	6738.4.7　Jarvis-Patrick聚类算法	6768.4.8　SNN密度	6788.4.9　基于SNN密度的聚类	6798.5　可伸缩的聚类算法	6818.5.1　可伸缩：一般问题和方法	6818.5.2　BIRCH	6848.5.3　CURE	6868.6　使用哪种聚类算法	6908.7　文献注释	6938.8　习题	699第9章　异常检测	7039.1　异常检测问题的特性	7059.1.1　异常的定义	7059.1.2　数据的性质	7069.1.3　如何使用异常检测	7079.2　异常检测方法的特性	7089.3　统计方法	7109.3.1　使用参数模型	7109.3.2　使用非参数模型	7149.3.3　对正常类和异常类建模	7159.3.4　评估统计意义	7179.3.5　优点与缺点	7189.4　基于邻近度的方法	7199.4.1　基于距离的异常分数	7199.4.2　基于密度的异常分数	7209.4.3　基于相对密度的异常分数	7229.4.4　优点与缺点	7239.5　基于聚类的方法	7249.5.1　发现异常簇	7249.5.2　发现异常实例	7259.5.3　优点与缺点	7289.6　基于重构的方法	7289.7　单类分类	7329.7.1　核函数的使用	7339.7.2　原点技巧	7349.7.3　优点与缺点	7389.8　信息论方法	7389.9　异常检测评估	7409.10　文献注释	7429.11　习题	749第10章　避免错误发现	75510.1　预备知识：统计检验	75610.1.1　显著性检验	75610.1.2　假设检验	76110.1.3　多重假设检验	76710.1.4　统计检验中的陷阱	77610.2　对零分布和替代分布建模	77810.2.1　生成合成数据集	78110.2.2　随机化类标	78210.2.3　实例重采样	78210.2.4　对检验统计量的分布建模	78310.3　分类问题的统计检验	78310.3.1　评估分类性能	78310.3.2　以多重假设检       验处理二分类问题	78510.3.3　模型选择中的多重假设检验	78610.4　关联分析的统计检验	78710.4.1　使用统计模型	78810.4.2　使用随机化方法	79410.5　聚类分析的统计检验	79510.5.1　为内部指标生成零分布	79610.5.2　为外部指标生成零分布	79810.5.3　富集	79810.6　异常检测的统计检验	80010.7　文献注释	80310.8　习题	808Contents1 Introduction	11.1 What  Is Data Mining?	41.2 Motivating Challenges	51.3 The Origins of Data Mining	71.4 Data Mining Tasks	91.5 Scope and Organization of  the Book	131.6 Bibliographic Notes	151.7 Exercises	212 Data	232.1 Types of Data	262.1.1 Attributes and Measurement	272.1.2 Types  of Data Sets	342.2 Data Quality	422.2.1 Measurement and Data Collection Issues	422.2.2 Issues Related to Applications	492.3 Data Preprocessing	502.3.1 Aggregation	512.3.2 Sampling	522.3.3 Dimensionality Reduction	56
