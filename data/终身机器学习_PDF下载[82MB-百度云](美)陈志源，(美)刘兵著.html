终身机器学习 PDF下载 (美)陈志源，(美)刘兵著 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711163212
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711163212
<p>书名:终身机器学习</p><p>作者:(美)陈志源，(美)刘兵著</p><p>页数:10,186页</p><p>定价:¥79.0</p><p>出版社:机械工业出版社</p><p>出版日期:2019-08-01</p><p>ISBN:9787111632122</p><p><h2>本书特色</h2></p>[<p>
本书介绍终身学习这种高级机器学习范式，这种范式通过积累过去的知识持续地学习，并将学到的知识用于帮助在未来进行其他学习和解决问题。相比之下，当前主流的机器学习范式都是孤立学习，即给定一个训练数据集，之后在这个数据集上运行机器学习算法以生成模型，然后再将该模型运用于预期的应用。这些范式不保留已经学到的知识，也不将其运用到后续的学习中。与孤立学习系统不同，人类只通过少量的样例就能实现有效学习，这是因为人类的学习是知识驱动的，即只需少量的数据或付出，就能利用过去已经学到的知识去学习新事物。终身学习的目标就是模仿人类的这种学习能力，因为一个没有持续学习能力的AI系统不能算作真正的智能。<br/>
自本书第1版出版以来，终身学习的研究在相对较短的时间内取得了显著的进展。出版第2版是为了扩展终身学习的定义，更新部分章节的内容，并添加一个新的章节来介绍深度神经网络中持续学习的内容，这部分内容在过去的两三年里一直被积极研究。部分章节的内容也进行了修改，使得内容更有条理，方便读者阅读。此外，作者希望为这一研究领域提出一个统一的框架。目前，在机器学习中有几个与终身学习密切相关的研究课题，特别是多任务学习、迁移学习以及元学习，因为它们也采用了知识共享和知识迁移的思想。本书之所以集中介绍这些技术并讨论其异同，目的是在介绍终身机器学习的同时，对该领域的重要研究成果和新想法进行全面回顾。本书适用于对机器学习、数据挖掘、自然语言处理或模式识别感兴趣的学生、研究人员和从业人员。
<br/>
</p>]<p><h2>内容简介</h2></p>[<p>本书介绍终身机器学习这种高级机器学习范式，该范式通过积累过去的知识持续地学习，并将所学到的知识用于帮助在未来进行其他学习和解决问题。本书适用于对机器学习、数据挖掘、自然语言处理或模式识别感兴趣的学生、研究人员。<br/>
<br/>
</p>]<p><h2>作者简介</h2></p>[<p>陈志源（ZhiyuanChen）在伊利诺伊大学芝加哥分校刘兵教授的指导下获得博士学位，博士论文题目为“终身机器学习：主题建模与分类”。他于2016年加入谷歌公司。他的研究兴趣包括机器学习、自然语言处理、文本挖掘、数据挖掘和竞价拍卖算法。他提出了几种终身机器学习算法，实现了自动从文本文档中挖掘信息，并在KDD、ICML、ACL、WWW、IJCAI和AAAI等主要会议上发表了超过15篇长篇研究论文。他还在IJCAI-2015、KDD-2016和EMNLP-2016上提供了三个关于终身机器学习的教程。他曾经是许多著名的自然语言处理、数据挖掘、人工智能和互联网研究会议的成员，并于2015年获得伊利诺伊州技术基金会颁发的最有潜力50人奖，以表彰他的学术贡献。<br/>陈志源（Zhiyuan
Chen）在伊利诺伊大学芝加哥分校刘兵教授的指导下获得博士学位，博士论文题目为“终身机器学习：主题建模与分类”。他于2016年加入谷歌公司。他的研究兴趣包括机器学习、自然语言处理、文本挖掘、数据挖掘和竞价拍卖算法。他提出了几种终身机器学习算法，实现了自动从文本文档中挖掘信息，并在KDD、ICML、ACL、WWW、IJCAI和AAAI等主要会议上发表了超过15篇长篇研究论文。他还在IJCAI-2015、KDD-2016和EMNLP-2016上提供了三个关于终身机器学习的教程。他曾经是许多著名的自然语言处理、数据挖掘、人工智能和互联网研究会议的成员，并于2015年获得伊利诺伊州技术基金会颁发的最有潜力50人奖，以表彰他的学术贡献。<br/>
<br/>
刘兵（Bing Liu）是伊利诺伊大学芝加哥分校的杰出教授，在爱丁堡大学获得了博士学位。他的研究兴趣包括终身学习、情感分析、数据挖掘、机器学习和自然语言处理，他在顶级会议和期刊上发表了大量论文，其中两篇论文获得了KDD 10年Test-of-Time奖，一篇论文获得WSDM 10年Test-of-Time奖。他也是4本书的作者，其中2本关于情感分析，1本关于终身学习，1本关于数据挖掘。他的一些工作被媒体广泛报道，包括《纽约时报》的头版文章。他是2018 ACM SIGKDD创新奖的获得者，也是很多顶级数据挖掘会议（包括KDD、ICDM、CIKM、WSDM、SDM和PAKDD）的程序主席。他同时是包括TKDE、TWEB、DMKD和TKDD在内的顶级期刊的副编辑，还是很多自然语言处理、人工智能、网络和数据挖掘会议的领域主席或者高级程序委员会成员，并且曾经是2013～2017年ACM SIGKDD的主席，是ACM、AAAI和IEEE会士。<br/>
<br/>
</p>]<p><h2>目录</h2></p>
    
译者序
前　言
致　谢
第1章　引言11.1　传统机器学习范式11.2　案例31.3　终身学习简史71.4　终身学习的定义91.5　知识类型和关键挑战141.6　评估方法和大数据的角色171.7　本书大纲18
第2章　相关学习范式202.1　迁移学习202.1.1　结构对应学习212.1.2　朴素贝叶斯迁移分类器222.1.3　迁移学习中的深度学习232.1.4　迁移学习与终身学习的区别242.2　多任务学习252.2.1　多任务学习中的任务相关性252.2.2　GO-MTL：使用潜在基础任务的多任务学习262.2.3　多任务学习中的深度学习282.2.4　多任务学习与终身学习的区别302.3　在线学习302.4　强化学习312.5　元学习322.6　小结34
第3章　终身监督学习353.1　定义和概述363.2　基于记忆的终身学习373.2.1　两个基于记忆的学习方法373.2.2　终身学习的新表达373.3　终身神经网络393.3.1　MTL网络393.3.2　终身EBNN403.4　ELLA：高效终身学习算法413.4.1　问题设定413.4.2　目标函数423.4.3　解决**个低效问题433.4.4　解决第二个低效问题453.4.5　主动的任务选择463.5　终身朴素贝叶斯分类473.5.1　朴素贝叶斯文本分类473.5.2　LSC的基本思想493.5.3　LSC技术503.5.4　讨论523.6　基于元学习的领域词嵌入523.7　小结和评估数据集54
第4章　持续学习与灾难性遗忘564.1　灾难性遗忘564.2　神经网络中的持续学习584.3　无遗忘学习614.4　渐进式神经网络624.5　弹性权重合并634.6　iCaRL：增量分类器与表示学习654.6.1　增量训练664.6.2　更新特征表示674.6.3　为新类构建范例集684.6.4　在iCaRL中完成分类684.7　专家网关694.7.1　自动编码网关694.7.2　测量训练的任务相关性704.7.3　为测试选择*相关的专家714.7.4　基于编码器的终身学习714.8　生成式重放的持续学习724.8.1　生成式对抗网络724.8.2　生成式重放734.9　评估灾难性遗忘744.10　小结和评估数据集75
第5章　开放式学习795.1　问题定义和应用805.2　基于中心的相似空间学习815.2.1　逐步更新CBS学习模型825.2.2　测试CBS学习模型845.2.3　用于未知类检测的CBS学习845.3　DOC：深度开放式分类875.3.1　前馈层和一对其余层875.3.2　降低开放空间风险895.3.3　DOC用于图像分类905.3.4　发现未知类905.4　小结和评估数据集91
第6章　终身主题建模936.1　终身主题建模的主要思想936.2　LTM：终身主题模型976.2.1　LTM模型976.2.2　主题知识挖掘996.2.3　融合过去的知识1006.2.4　Gibbs采样器的条件分布1026.3　AMC：少量数据的终身主题模型1026.3.1　AMC整体算法1036.3.2　挖掘must-link知识1046.3.3　挖掘cannot-link知识1076.3.4　扩展的Pólya瓮模型1086.3.5　Gibbs采样器的采样分布1106.4　小结和评估数据集112
第7章　终身信息提取1147.1　NELL：永不停止语言学习器1147.1.1　NELL结构1177.1.2　NELL中的提取器与学习1187.1.3　NELL中的耦合约束1207.2　终身评价目标提取1217.2.1　基于推荐的终身学习1227.2.2　AER算法1237.2.3　知识学习1247.2.4　使用过去知识推荐1257.3　在工作中学习1267.3.1　条件随机场1277.3.2　一般依赖特征1287.3.3　L-CRF算法1307.4　Lifelong-RL：终身松弛标记法1317.4.1　松弛标记法1327.4.2　终身松弛标记法1337.5　小结和评估数据集133
第8章　聊天机器人的持续知识学习1358.1　LiLi：终身交互学习与推理1368.2　LiLi的基本思想1398.3　LiLi的组件1418.4　运行示例1428.5　小结和评估数据集142
第9章　终身强化学习1449.1　基于多环境的终身强化学习1469.2　层次贝叶斯终身强化学习1479.2.1　动机1479.2.2　层次贝叶斯方法1489.2.3　MTRL算法1499.2.4　更新层次模型参数1509.2.5　对MDP进行采样1519.3　PG-ELLA：终身策略梯度强化学习1529.3.1　策略梯度强化学习1529.3.2　策略梯度终身学习设置1549.3.3　目标函数和优化1549.3.4　终身学习的安全策略搜索1569.3.5　跨领域终身强化学习1569.4　小结和评估数据集157
第10章　结论及未来方向159
参考文献164

