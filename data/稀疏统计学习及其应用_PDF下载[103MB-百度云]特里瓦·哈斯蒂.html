稀疏统计学习及其应用 PDF下载 特里瓦·哈斯蒂 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711547261
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711547261
<p>书名:稀疏统计学习及其应用</p><p>作者:特里瓦·哈斯蒂</p><p>页数:284</p><p>定价:¥89.0</p><p>出版社:人民邮电出版社</p><p>出版日期:2018-01-01</p><p>ISBN:9787115472618</p><p><h2>本书特色</h2></p>[<p>
稀疏统计模型只具有少数非零参数或权重，经典地体现了化繁为简的理念，因而广泛应用于诸多领域。本书就稀疏性统计学习做出总结，以 lasso方法为中心，层层推进，逐渐囊括其他方法，深入探讨诸多稀疏性问题的求解和应用；不仅包含大量的例子和清晰的图表，还附有文献注释和课后练习，是深入学习统计学知识的参考。
本书适合算法、统计学和机器学习专业人士。
                                        </p>]<p><h2>作者简介</h2></p>[<p>Trevor Hastie 美国统计学家和计算机科学家，斯坦福大学统计学教授，英国皇家统计学会、国际数理统计协会和美国统计学会会士。Hastie参与开发了R中的大部分统计建模软件和环境，发明了主曲线和主曲面。 <br/><br/>Robert Tibshirani 斯坦福大学统计学教授，国际数理统计协会、美国统计学会和加拿大皇家学会会士，1996年COPSS总统奖得主，提出lasso方法。Hastie和Tibshirani都是统计学习领域的泰山北斗，两人合著了The Elements of Statistical Learning，还合作讲授斯坦福大学的公开课“统计学习”。 <br/><br/>Martin Wainwright 毕业于MIT，加州大学伯克利分校教授，以对统计与计算交叉学的理论和方法研究而闻名于学界，主要关注高维统计、机器学习、图模型和信息理论。2014年COPSS总统奖得主。 <br/>Trevor Hastie 美国统计学家和计算机科学家，斯坦福大学统计学教授，英国皇家统计学会、国际数理统计协会和美国统计学会会士。Hastie参与开发了R中的大部分统计建模软件和环境，发明了主曲线和主曲面。 <br/><br/>Robert Tibshirani 斯坦福大学统计学教授，国际数理统计协会、美国统计学会和加拿大皇家学会会士，1996年COPSS总统奖得主，提出lasso方法。Hastie和Tibshirani都是统计学习领域的泰山北斗，两人合著了The Elements of Statistical Learning，还合作讲授斯坦福大学的公开课“统计学习”。 <br/><br/>Martin Wainwright 毕业于MIT，加州大学伯克利分校教授，以对统计与计算交叉学的理论和方法研究而闻名于学界，主要关注高维统计、机器学习、图模型和信息理论。2014年COPSS总统奖得主。 <br/><br/>刘波（译者） 博士，重庆工商大学计算机科学与信息工程学院教师，主要从事机器学习理论、计算机视觉和最优化技术研究，同时爱好Hadoop和Spark平台上的大数分析，也对Linux平台的编程和Oracle数据库感兴趣。 <br/><br/>景鹏杰（译者） 硕士，毕业于上海交通大学。硕士阶段主要从事模式识别与数据挖掘基础理论、生物医学大数据挖掘与建模等工作，在国际期刊及会议Bioinformatics，CCPR等上面发表数篇论文。目前从事期货交易系统开发工作。 </p>]<p><h2>目录</h2></p>
    第 1章引言  1

第 2章 lasso线性模型   6 

2.1引言  6 

2.2 lasso估计   7 

2.3交叉验证和推断  10 
2.4 lasso解的计算  12 

2.4.1基于单变量的软阈值法  12 
2.4.2基于多变量的循环坐标下降法  13 

2.4.3软阈值与正交基      15 
2.5自由度  15 

2.6 lasso解    16 
2.7理论概述        17 
2.8非负 garrote       17 
2.9乌q惩罚和贝叶斯估计     19 
2.10一些观点      20
习题  21
第 3章广义线性模型    24 
3.1引言        24 
3.2逻辑斯蒂回归模型   26 

3.2.1示例：文本分类  27 

3.2.2算法  29 

3.3多分类逻辑斯蒂回归   30 
3.3.1示例：手写数字  31 

3.3.2算法  32 

3.3.3组 lasso多分类  33 

3.4对数线性模型及泊松广义线性模型     33 
3.5 Cox比例风险模型   35 

3.5.1交叉验证  37 

3.5.2预验证   38 

3.6支持向量机   39 

3.7计算细节及 glmnet       43
参考文献注释   44
习题  45
第 4章广义 lasso惩罚  47 
4.1引言        47 
4.2弹性网惩罚   47 

4.3组 lasso  50 
4.3.1组 lasso计算      53 
4.3.2稀疏组 lasso  54 

4.3.3重叠组 lasso  56 

4.4稀疏加法模型和组 lasso     59 
4.4.1加法模型和 back.tting  59 
4.4.2稀疏加法模型和 back.tting  60 

4.4.3优化方法与组 lasso     61 
4.4.4稀疏加法模型的多重惩罚         64 
4.5融合 lasso  65 

4.5.1拟合融合 lasso   66 

4.5.2趋势滤波  69 

4.5.3近保序回归   70 

4.6非凸惩罚        72
参考文献注释   74
习题  75
第 5章优化方法  80 
5.1引言        80 
5.2凸优化条件   80 

5.2.1优化可微问题        80 
5.2.2非可微函数和次梯度     83 
5.3梯度下降        84 
5.3.1无约束的梯度下降      84 
5.3.2投影梯度法   86 

5.3.3近点梯度法   87 

5.3.4加速梯度方法        90 
5.4坐标下降        92 
5.4.1可分性和坐标下降      93 
5.4.2线性回归和 lasso  94 

5.4.3逻辑斯蒂回归和广义线性模型  97 

5.5仿真研究        99 
5.6z小角回归  100 

5.7交替方向乘子法      103 
5.8优化?Czui小化算法   104 

5.9双凸问题和交替zui小化  105 

5.10筛选规则      108
参考文献注释  111
附录 A lasso的对偶   112
附录 B DPP规则的推导  113
习题           114
第 6章统计推断  118 
6.1贝叶斯 lasso       118 
6.2自助法   121 

6.3 lasso法的后选择推断  125 

6.3.1协方差检验    125 
6.3.2选择后推断的更广方案          128 
6.3.3检验何种假设       133 
6.3.4回到向前逐步回归    134 
6.4通过去偏 lasso推断  134 
6.5后选择推断的其他建议  136
参考文献注释  137
习题           138
第 7章矩阵的分解、近似及填充    141 
7.1引言   141 

7.2奇异值分解  142 

7.3缺失数据和矩阵填充      143 
7.3.1 Net.x电影挑战赛    144 
7.3.2基于原子范数的矩阵填充  146 

7.3.3矩阵填充的理论结果    149 
7.3.4间隔分解及相关方法  153 

7.4减秩回归     154 
7.5通用矩阵回归框架  156 

7.6惩罚矩阵分解     157 
7.7矩阵分解的相加形式      160 
参考文献注释  164
习题           165
第 8章稀疏多元方法   169 
8.1引言   169 

8.2稀疏组成分分析      169 
8.2.1背景  169 

8.2.2稀疏主成分    171 
8.2.3秩大于 1的解     174 
8.2.4基于 Fantope投影的稀疏 PCA       176 
8.2.5稀疏自编码和深度学习          176 
8.2.6稀疏 PCA的一些理论    178 
8.3稀疏典型相关分析  179 

8.4稀疏线性判别分析  182 

8.4.1标准理论和贝叶斯规则          182 
8.4.2*近收缩中心       183 
8.4.3 Fisher线性判别分析   184 

8.4.4评分  188 

8.5稀疏聚类     190 
8.5.1聚类的一些背景知识    191 
8.5.2稀疏层次聚类       191 
8.5.3稀疏 K均值聚类    192 
8.5.4凸聚类  193
参考文献注释  195
习题           196
第 9章图和模型选择   202 
9.1引言   202 

9.2图模型基础  202 

9.2.1分解和马尔可夫特性    202 
9.2.2几个例子  204 

9.3基于惩罚似然的图选择  206 

9.3.1高斯模型的全局似然性          207 
9.3.2图 lasso算法   208 

9.3.3利用块对角化结构    210 
9.3.4图 lasso的理论保证  211 

9.3.5离散模型的全局似然性          212 
9.4基于条件推断的图选择  213 

9.4.1高斯分布下基于近邻的似然概率   214 

9.4.2离散模型下基于近邻的似然概率   214 

9.4.3混合模型下的伪似然概率  217 

9.5带隐变量的图模型  218
参考文献注释  219
习题           221
第 10章信号近似与压缩感知     225 
10.1引言  225 

10.2信号与稀疏表示   225 

10.2.1正交基  225 

10.2.2用正交基逼近      228 
10.2.3用过完备基来重构    229 
10.3随机投影与近似   231 

10.3.1 Johnson?CLindenstrauss近似  231 

10.3.2压缩感知    232 
10.4乌0恢复与乌1恢复之间的等价性      234 
10.4.1受限零空间性质      235 
10.4.2受限零空间的充分条件   235 

10.4.3证明   237
参考文献注释  238
习题           239
第 11章 lasso的理论结果  242 
11.1引言  242 

11.1.1损失函数类型      242 
11.1.2稀疏模型类型      243 
11.2 lasso乌2误差的界限      244 
11.2.1经典情形中的强凸性           244 
11.2.2回归受限特征值      245 
11.2.3基本一致性结果      246 
11.3预测误差的界    250 
11.4线性回归中的支持恢复   252 

11.4.1 lasso的变量选择一致性         252 
11.4.2定理 11.3的证明     256 
11.5超越基础 lasso  259 

参考文献注释  260
习题           261
参考文献           264
