自适应滤波器原理:英文版 PDF下载 (加)SimonHaykin著 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712132251
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712132251
<p>书名:自适应滤波器原理:英文版</p><p>作者:(加)Simon Haykin著</p><p>页数:907页</p><p>定价:¥149.0</p><p>出版社:电子工业出版社</p><p>出版日期:2017-07-01</p><p>ISBN:9787121322518</p><p><h2>本书特色</h2></p>[<p>
本书是自适应信号处理领域的一本经典教材。全书共17章，系统全面、深入浅出地讲述了自适应信号处理的基本理论与方法，充分反映了近年来该领域的新理论、新技术和新应用。内容包括：*过程与模型、维纳滤波器、线性预测、*速下降法、*梯度下降法、*小均方（LMS）算法、归一化LMS自适应算法及其推广、分块自适应滤波器、*小二乘法、递归*小二乘（RLS）算法、鲁棒性、有限字长效应、非平衡环境下的自适应、卡尔曼滤波器、平方根自适应滤波算法、阶递归自适应滤波算法、盲反卷积，以及它们在通信与信息系统中的应用。
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书作者是国际知名的教材作者，其编著的基本教材“信号与系统”“通信系统”“自适应滤波器原理”均是国外的优秀畅销教材，已被多所大学采用。本书内容紧跟时代，不断更新。正因为这样，该书备受读者欢迎，影响与日俱增，赢得很高的声誉。 </p>]<p><h2>作者简介</h2></p>[<p>Simon Haykin：IEEE会士、加拿大皇家学会会士，毕业于英国伯明翰大学电子工程系。现为加拿大McMaster大学的Distinguished University教授，认知系统实验室主任。2002年获国际无线电科学联盟(URSI）颁发的Henry
Booker金质奖章。在无线通信与信号处理领域的多个方面著述颇丰，主要研究方向为自适应信号处理与智能信号处理、无线通信与雷达技术，近年来特别关注认知无线电和认知雷达方面的研究。</p>]<p><h2>目录</h2></p>
    ContentsBackground and Preview 11. The Filtering Problem 12. Linear Optimum Filters 43. Adaptive Filters 44. Linear Filter Structures 65. Approaches to the Development of Linear Adaptive Filters 126. Adaptive Beamforming 137. Four Classes of Applications 178. Historical Notes 20Chapter 1 Stochastic Processes and Models 301.1 Partial Characterization of a Discrete-Time Stochastic Process 301.2 Mean Ergodic Theorem 321.3 Correlation Matrix 341.4 Correlation Matrix of Sine Wave Plus Noise 391.5 Stochastic Models 401.6 Wold Decomposition 461.7 Asymptotic Stationarity of an Autoregressive Process 491.8 Yule?CWalker Equations 511.9 Computer Experiment: Autoregressive Process of Order Two 521.10 Selecting the Model Order 601.11 Complex Gaussian Processes 631.12 Power Spectral Density 651.13 Properties of Power Spectral Density 671.14 Transmission of a Stationary Process Through a Linear Filter 691.15 Cramér Spectral Representation for a Stationary Process 721.16 Power Spectrum Estimation 741.17 Other Statistical Characteristics of a Stochastic Process 771.18 Polyspectra 781.19 Spectral-Correlation Density 811.20 Summary and Discussion 84Problems 85Chapter 2 Wiener Filters 902.1 Linear Optimum Filtering: Statement of the Problem 902.2 Principle of Orthogonality 922.3 Minimum Mean-Square Error 962.4 Wiener?CHopf Equations 982.5 Error-Performance Surface 1002.6 Multiple Linear Regression Model 1042.7 Example 1062.8 Linearly Constrained Minimum-Variance Filter 1112.9 Generalized Sidelobe Cancellers 1162.10 Summary and Discussion 122Problems 124Chapter 3 Linear Prediction 1323.1 Forward Linear Prediction 1323.2 Backward Linear Prediction 1393.3 Levinson?CDurbin Algorithm 1443.4 Properties of Prediction-Error Filters 1533.5 Schur?CCohn Test 1623.6 Autoregressive Modeling of a Stationary Stochastic Process 1643.7 Cholesky Factorization 1673.8 Lattice Predictors 1703.9 All-Pole, All-Pass Lattice Filter 1753.10 Joint-Process Estimation 1773.11 Predictive Modeling of Speech 1813.12 Summary and Discussion 188Problems 189Chapter 4 Method of Steepest Descent 1994.1 Basic Idea of the Steepest-Descent Algorithm 1994.2 The Steepest-Descent Algorithm Applied to the Wiener Filter 2004.3 Stability of the Steepest-Descent Algorithm 2044.4 Example 2094.5 The Steepest-Descent Algorithm Viewed as a Deterministic Search Method 2214.6 Virtue and Limitation of the Steepest-Descent Algorithm 2224.7 Summary and Discussion 223Problems 224Chapter 5 Method of Stochastic Gradient Descent 2285.1 Principles of Stochastic Gradient Descent 2285.2 Application 1: Least-Mean-Square (LMS) Algorithm 2305.3 Application 2: Gradient-Adaptive Lattice Filtering Algorithm 2375.4 Other Applications of Stochastic Gradient Descent 2445.5 Summary and Discussion 245Problems 246Chapter 6 The Least-Mean-Square (LMS) Algorithm 2486.1 Signal-Flow Graph 2486.2 Optimality Considerations 2506.3 Applications 2526.4 Statistical Learning Theory 2726.5 Transient Behavior and Convergence Considerations 2836.6 Efficiency 2866.7 Computer Experiment on Adaptive Prediction 2886.8 Computer Experiment on Adaptive Equalization 2936.9 Computer Experiment on a Minimum-Variance Distortionless-ResponseBeamformer3026.10 Summary and Discussion 306Problems 308Chapter 7 Normalized Least-Mean-Square (LMS) Algorithm and ItsGeneralization 3157.1 Normalized LMS Algorithm: The Solution to a Constrained Optimization Problem 3157.2 Stability of the Normalized LMS Algorithm 3197.3 Step-Size Control for Acoustic Echo Cancellation 3227.4 Geometric Considerations Pertaining to the Convergence Process for Real-ValuedData 3277.5 Affine Projection Adaptive Filters 3307.6 Summary and Discussion 334Problems 335Chapter 8 Block-Adaptive Filters 3398.1 Block-Adaptive Filters: Basic Ideas 3408.2 Fast Block LMS Algorithm 3448.3 Unconstrained Frequency-Domain Adaptive Filters 3508.4 Self-Orthogonalizing Adaptive Filters 3518.5 Computer Experiment on Adaptive Equalization 3618.6 Subband Adaptive Filters 3678.7 Summary and Discussion 375Problems 376Chapter 9 Method of Least-Squares 3809.1 Statement of the Linear Least-Squares Estimation Problem 3809.2 Data Windowing 3839.3 Principle of Orthogonality Revisited 3849.4 Minimum Sum of Error Squares 3879.5 Normal Equations and Linear Least-Squares Filters 3889.6 Time-Average Correlation Matrix ≥ 3919.7 Reformulation of the Normal Equations in Terms of Data Matrices 3939.8 Properties of Least-Squares Estimates 3979.9 Minimum-Variance Distortionless Response (MVDR) Spectrum Estimation 4019.10 Regularized MVDR Beamforming 4049.11 Singular-Value Decomposition 4099.12 Pseudoinverse 4169.13 Interpretation of Singular Values and Singular Vectors 4189.14 Minimum-Norm Solution to the Linear Least-Squares Problem 4199.15 Normalized LMS Algorithm Viewed as the Minimum-Norm Solution to anUnderdetermined Least-Squares Estimation Problem 4229.16 Summary and Discussion 424Problems 425Chapter 10 The Recursive Least-Squares (RLS) Algorithm 43110.1 Some Preliminaries 43110.2 The Matrix Inversion Lemma 43510.3 The Exponentially Weighted RLS Algorithm 43610.4 Selection of the Regularization Parameter 43910.5 Updated Recursion for the Sum of Weighted Error Squares 44110.6 Example: Single-Weight Adaptive Noise Canceller 44310.7 Statistical Learning Theory 44410.8 Efficiency 44910.9 Computer Experiment on Adaptive Equalization 45010.10 Summary and Discussion 453Problems 454Chapter 11 Robustness 45611.1 Robustness, Adaptation, and Disturbances 45611.2 Robustness: Preliminary Considerations Rooted in H∞ Optimization 45711.3 Robustness of the LMS Algorithm 46011.4 Robustness of the RLS Algorithm 46511.5 Comparative Evaluations of the LMS and RLS Algorithms from the Perspective ofRobustness47011.6 Risk-Sensitive Optimality 47011.7 Trade-Offs Between Robustness and Efficiency 47211.8 Summary and Discussion 474Problems 474Chapter 12 Finite-Precision Effects 47912.1 Quantization Errors 48012.2 Least-Mean-Square (LMS) Algorithm 48212.3 Recursive Least-Squares (RLS) Algorithm 49112.4 Summary and Discussion 497Problems 498Chapter 13 Adaptation in Nonstationary Environments 50013.1 Causes and Consequences of Nonstationarity 50013.2 The System Identification Problem 50113.3 Degree of Nonstationarity 50413.4 Criteria for Tracking Assessment 50513.5 Tracking Performance of the LMS Algorithm 50713.6 Tracking Performance of the RLS Algorithm 51013.7 Comparison of the Tracking Performance of LMS and RLS Algorithms 51413.8 Tuning of Adaptation Parameters 51813.9 Incremental Delta-Bar-Delta (IDBD) Algorithm 52013.10 Autostep Method 52613.11 Computer Experiment: Mixture of Stationary and Nonstationary EnvironmentalData 53013.12 Summary and Discussion 534Problems 535Chapter 14 Kalman Filters 54014.1 Recursive Minimum Mean-Square Estimation for Scalar Random Variables 54114.2 Statement of the Kalman Filtering Problem 54414.3 The Innovations Process 54714.4 Estimation of the State Using the Innovations Process 54914.5 Filtering 55514.6 Initial Conditions 55714.7 Summary of the Kalman Filter 55814.8 Optimality Criteria for Kalman Filtering 55914.9 Kalman Filter as the Unifying Basis for RLS Algorithms 56114.10 Covariance Filtering Algorithm 56614.11 Information Filtering Algorithm 56814.12 Summary and Discussion 571Problems 572C
